{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c72b164-a3e9-4bcd-8d09-57dc6fa03d20",
   "metadata": {},
   "source": [
    "## PytorchLightning: Image Classification using CIFAR10 and ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af180c05-b41b-49bb-938c-86eeaa357d56",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc88a00-f96d-4d03-b974-b2498ccff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501a8b1-7a85-4f2b-9296-6b0054274e4e",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b541c456-c453-404f-9b02-14335a59f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_set = CIFAR10(os.getcwd(), download=True, train=True, transform=transforms.ToTensor())\n",
    "test_set = CIFAR10(os.getcwd(), download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0301520-f780-4f41-9143-452c3e17265c",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53ea83c-50b6-4322-8e53-44641859e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000\n",
      "Valid size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_set_size = int(len(data_set) * 0.8)\n",
    "valid_set_size = len(data_set) - train_set_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator = seed)\n",
    "\n",
    "print(f\"Train size: {train_set_size}\")\n",
    "print(f\"Valid size: {valid_set_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8cd1-053a-4ba1-b2a3-494fb4824eba",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664b08f3-e688-4902-a3ed-e7fa772119e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684f1a8-2521-4ad9-8b32-582c8718a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImagenetTransferLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52a7b2-10f5-4182-b1bd-377f9b628e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 512)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 512)\n",
    "test_loader = DataLoader(test_set, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158c18c-f8aa-4ad2-9b70-73fd1956d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger('resnet50_level6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c3e6f-c3c5-455f-9546-f416baf7462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, \n",
    "                     default_root_dir=\"resnet50_level6/\",\n",
    "                     enable_checkpointing=True,\n",
    "                     logger=tb_logger)\n",
    "\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de9bc3-a9b1-4d25-b0a0-79fcfa77c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38746ee2-2cf0-413f-9b21-df183d1b3d57",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae083f4-9711-4e07-b24b-6f058ee30801",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = ImagenetTransferLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c137807-fdfb-4b33-bb53-697ab68dc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = model_resnet.load_from_checkpoint(\"resnet50_level6/lightning_logs/version_0/checkpoints/epoch=4-step=395.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "847ee5ae-0515-4efc-850b-fc85b20b03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 224, 224, dtype=torch.float).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffafc47-7a24-4d9b-8cae-00a12eb736c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable randomness, dropout, etc...\n",
    "model_resnet.eval()\n",
    "\n",
    "# predict with the model\n",
    "y_hat = model_resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b3956-4f2e-450a-ba4a-393c797616a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
