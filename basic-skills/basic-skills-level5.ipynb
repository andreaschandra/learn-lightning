{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c72b164-a3e9-4bcd-8d09-57dc6fa03d20",
   "metadata": {},
   "source": [
    "## PytorchLightning: Image Classification using CIFAR10 and ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af180c05-b41b-49bb-938c-86eeaa357d56",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc88a00-f96d-4d03-b974-b2498ccff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501a8b1-7a85-4f2b-9296-6b0054274e4e",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b541c456-c453-404f-9b02-14335a59f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_set = CIFAR10(os.getcwd(), download=True, train=True, transform=transforms.ToTensor())\n",
    "test_set = CIFAR10(os.getcwd(), download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0301520-f780-4f41-9143-452c3e17265c",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53ea83c-50b6-4322-8e53-44641859e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000\n",
      "Valid size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_set_size = int(len(data_set) * 0.8)\n",
    "valid_set_size = len(data_set) - train_set_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator = seed)\n",
    "\n",
    "print(f\"Train size: {train_set_size}\")\n",
    "print(f\"Valid size: {valid_set_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8cd1-053a-4ba1-b2a3-494fb4824eba",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b08f3-e688-4902-a3ed-e7fa772119e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684f1a8-2521-4ad9-8b32-582c8718a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImagenetTransferLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52a7b2-10f5-4182-b1bd-377f9b628e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 512)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 512)\n",
    "test_loader = DataLoader(test_set, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158c18c-f8aa-4ad2-9b70-73fd1956d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger('cifar10_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c3e6f-c3c5-455f-9546-f416baf7462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, \n",
    "                     default_root_dir=\"resnet50/\",\n",
    "                     enable_checkpointing=True,\n",
    "                     logger=tb_logger)\n",
    "\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de9bc3-a9b1-4d25-b0a0-79fcfa77c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335bf3-1f89-4464-9c0e-246a80dc8db3",
   "metadata": {},
   "source": [
    "### Adding argument parser for py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b68476-c833-4b1e-9eb4-8ded8b43ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b0419-fe22-4b6a-81b0-56b1d2efd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f6429-09f9-47a2-a852-2e70ec5f15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer arguments\n",
    "parser.add_argument(\"--devices\", type=int, default=2)\n",
    "\n",
    "# Hyperparameters for the model\n",
    "parser.add_argument(\"--layer_1_dim\", type=int, default=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ae9c9-d53d-412b-9c20-48ef95c27f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the user inputs and defaults (returns a argparse.Namespace)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc0fea-ba5f-4cc1-9a19-bde7812f245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parsed arguments in your program\n",
    "trainer = Trainer(devices=args.devices)\n",
    "model = ImagenetTransferLearning(ImagenetTransferLearning=args.layer_1_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d9129-4fde-4cda-8ce5-e18eb4c2c602",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc9388-16dc-4300-be67-e36babb2dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_debug():\n",
    "    x = 2\n",
    "    print(x)\n",
    "    pdb.set_trace()\n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989519f6-6a08-46df-9ee4-2fdc1cc93bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e5a65-547e-4d9d-a2d1-3e2cb1aeddae",
   "metadata": {},
   "source": [
    "### Run all your model code once quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419dbdb1-4c7b-4318-b096-a5d244d1f686",
   "metadata": {},
   "source": [
    "The fast_dev_run argument in the trainer runs 5 batch of training, validation, test and prediction data through your trainer to see if there are any bugs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b3c36-525a-4899-b7a7-f9e6d5af0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default 5 batch\n",
    "trainer = pl.Trainer(fast_dev_run=True, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa7402-30ad-4bb5-a651-72fc2151532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e019d1-7b59-4a3d-97db-c07ef7bb09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change default batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5a192-50a1-481a-ab7e-31126c6039c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Trainer(fast_dev_run=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f75fe-15ce-4af1-9767-7100436bb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416fdd0-6238-4647-8df7-8374462b3b95",
   "metadata": {},
   "source": [
    "### Shorten the epoch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab4551-3b3b-4cea-b085-91a84764a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only 20% of training data and 10% of val data\n",
    "trainer = pl.Trainer(limit_train_batches=0.2, limit_val_batches=0.1, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105410c3-1f72-4c12-a50d-e3dd3e15fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ddb367-dc19-4b55-adeb-f6c7493a881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 10 batches of train and 5 batches of val\n",
    "trainer = pl.Trainer(limit_train_batches=10, limit_val_batches=5, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd996444-cef7-4feb-be9b-92e92bf12fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e8ca6-2d78-408e-ab50-4cc26cffdb5b",
   "metadata": {},
   "source": [
    "### Run a Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb1c24-1e61-4297-a530-827d90a5eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(num_sanity_val_steps=2, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e26bb-3ac0-48d9-be77-649c76d53974",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71169922-5e2a-4e26-ad2b-2d2f94940e4f",
   "metadata": {},
   "source": [
    "### Print LightningModule weights summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b8217-20bb-4392-8565-d8ed2a1bd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f3b5d-e9f7-488c-9a5b-378c1beedb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(callbacks=[ModelSummary(max_depth=-1)], \n",
    "                     limit_train_batches=10, \n",
    "                     limit_val_batches=5, \n",
    "                     max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0bdbe-bb80-4ac8-8fb7-0c1914d04abb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386c407-bcc7-40ed-b8fa-d8d489e8d390",
   "metadata": {},
   "source": [
    "To print the model summary if .fit() is not called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec427ca2-9aa9-4985-8d4e-eece5ca1a3af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "summary = ModelSummary(model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66663d78-8c8c-4e5a-827f-119137515578",
   "metadata": {},
   "source": [
    "### Print input output layer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea9dda-8751-4654-9025-cc86f554ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=10, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.example_input_array = torch.Tensor(32, 3, 228, 228)\n",
    "        \n",
    "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        x = input_\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f220d-907c-48f4-a003-8254be3441fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "model = ImagenetTransferLearning()\n",
    "summary = ModelSummary(model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aae017-2f3d-41ed-94b6-2bad54b698a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
