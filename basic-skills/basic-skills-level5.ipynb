{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c72b164-a3e9-4bcd-8d09-57dc6fa03d20",
   "metadata": {},
   "source": [
    "## PytorchLightning: Image Classification using CIFAR10 and ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af180c05-b41b-49bb-938c-86eeaa357d56",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc88a00-f96d-4d03-b974-b2498ccff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501a8b1-7a85-4f2b-9296-6b0054274e4e",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b541c456-c453-404f-9b02-14335a59f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_set = CIFAR10(os.getcwd(), download=True, train=True, transform=transforms.ToTensor())\n",
    "test_set = CIFAR10(os.getcwd(), download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0301520-f780-4f41-9143-452c3e17265c",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53ea83c-50b6-4322-8e53-44641859e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000\n",
      "Valid size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_set_size = int(len(data_set) * 0.8)\n",
    "valid_set_size = len(data_set) - train_set_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator = seed)\n",
    "\n",
    "print(f\"Train size: {train_set_size}\")\n",
    "print(f\"Valid size: {valid_set_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8cd1-053a-4ba1-b2a3-494fb4824eba",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664b08f3-e688-4902-a3ed-e7fa772119e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5684f1a8-2521-4ad9-8b32-582c8718a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImagenetTransferLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d52a7b2-10f5-4182-b1bd-377f9b628e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 512)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 512)\n",
    "test_loader = DataLoader(test_set, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c158c18c-f8aa-4ad2-9b70-73fd1956d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger('cifar10_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44c3e6f-c3c5-455f-9546-f416baf7462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | Sequential       | 23.5 M\n",
      "1 | classifier        | Linear           | 20.5 K\n",
      "2 | criterion         | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, \n",
    "                     default_root_dir=\"resnet50/\",\n",
    "                     enable_checkpointing=True,\n",
    "                     logger=tb_logger)\n",
    "\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de9bc3-a9b1-4d25-b0a0-79fcfa77c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335bf3-1f89-4464-9c0e-246a80dc8db3",
   "metadata": {},
   "source": [
    "### Adding argument parser for py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b68476-c833-4b1e-9eb4-8ded8b43ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b0419-fe22-4b6a-81b0-56b1d2efd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f6429-09f9-47a2-a852-2e70ec5f15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer arguments\n",
    "parser.add_argument(\"--devices\", type=int, default=2)\n",
    "\n",
    "# Hyperparameters for the model\n",
    "parser.add_argument(\"--layer_1_dim\", type=int, default=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ae9c9-d53d-412b-9c20-48ef95c27f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the user inputs and defaults (returns a argparse.Namespace)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc0fea-ba5f-4cc1-9a19-bde7812f245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parsed arguments in your program\n",
    "trainer = Trainer(devices=args.devices)\n",
    "model = ImagenetTransferLearning(ImagenetTransferLearning=args.layer_1_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d9129-4fde-4cda-8ce5-e18eb4c2c602",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc9388-16dc-4300-be67-e36babb2dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_debug():\n",
    "    x = 2\n",
    "    print(x)\n",
    "    pdb.set_trace()\n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989519f6-6a08-46df-9ee4-2fdc1cc93bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e5a65-547e-4d9d-a2d1-3e2cb1aeddae",
   "metadata": {},
   "source": [
    "### Run all your model code once quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419dbdb1-4c7b-4318-b096-a5d244d1f686",
   "metadata": {},
   "source": [
    "The fast_dev_run argument in the trainer runs 5 batch of training, validation, test and prediction data through your trainer to see if there are any bugs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64b3c36-525a-4899-b7a7-f9e6d5af0c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "# default 5 batch\n",
    "trainer = pl.Trainer(fast_dev_run=True, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fa7402-30ad-4bb5-a651-72fc2151532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | Sequential       | 23.5 M\n",
      "1 | classifier        | Linear           | 20.5 K\n",
      "2 | criterion         | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03c63d5d098431b99abd6b646fd2b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e019d1-7b59-4a3d-97db-c07ef7bb09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change default batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f5a192-50a1-481a-ab7e-31126c6039c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 7 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x1f1a4d3e9d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Trainer(fast_dev_run=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331f75fe-15ce-4af1-9767-7100436bb0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | Sequential       | 23.5 M\n",
      "1 | classifier        | Linear           | 20.5 K\n",
      "2 | criterion         | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416fdd0-6238-4647-8df7-8374462b3b95",
   "metadata": {},
   "source": [
    "### Shorten the epoch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28ab4551-3b3b-4cea-b085-91a84764a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# use only 20% of training data and 10% of val data\n",
    "trainer = pl.Trainer(limit_train_batches=0.2, limit_val_batches=0.1, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "105410c3-1f72-4c12-a50d-e3dd3e15fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | Sequential       | 23.5 M\n",
      "1 | classifier        | Linear           | 20.5 K\n",
      "2 | criterion         | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ccfcb3f7a546fd8169bb2719a13d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3ddb367-dc19-4b55-adeb-f6c7493a881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# use 10 batches of train and 5 batches of val\n",
    "trainer = pl.Trainer(limit_train_batches=10, limit_val_batches=5, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd996444-cef7-4feb-be9b-92e92bf12fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | Sequential       | 23.5 M\n",
      "1 | classifier        | Linear           | 20.5 K\n",
      "2 | criterion         | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccc0af6874f42679768c27aa28e2eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e8ca6-2d78-408e-ab50-4cc26cffdb5b",
   "metadata": {},
   "source": [
    "### Run a Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52fb1c24-1e61-4297-a530-827d90a5eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(num_sanity_val_steps=2, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "849e26bb-3ac0-48d9-be77-649c76d53974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | Sequential       | 23.5 M\n",
      "1 | classifier        | Linear           | 20.5 K\n",
      "2 | criterion         | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7089473f184007971c525937287994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71169922-5e2a-4e26-ad2b-2d2f94940e4f",
   "metadata": {},
   "source": [
    "### Print LightningModule weights summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "895b8217-20bb-4392-8565-d8ed2a1bd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "539f3b5d-e9f7-488c-9a5b-378c1beedb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(callbacks=[ModelSummary(max_depth=-1)], \n",
    "                     limit_train_batches=10, \n",
    "                     limit_val_batches=5, \n",
    "                     max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9e0bdbe-bb80-4ac8-8fb7-0c1914d04abb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "    | Name                               | Type              | Params\n",
      "---------------------------------------------------------------------------\n",
      "0   | feature_extractor                  | Sequential        | 23.5 M\n",
      "1   | feature_extractor.0                | Conv2d            | 9.4 K \n",
      "2   | feature_extractor.1                | BatchNorm2d       | 128   \n",
      "3   | feature_extractor.2                | ReLU              | 0     \n",
      "4   | feature_extractor.3                | MaxPool2d         | 0     \n",
      "5   | feature_extractor.4                | Sequential        | 215 K \n",
      "6   | feature_extractor.4.0              | Bottleneck        | 75.0 K\n",
      "7   | feature_extractor.4.0.conv1        | Conv2d            | 4.1 K \n",
      "8   | feature_extractor.4.0.bn1          | BatchNorm2d       | 128   \n",
      "9   | feature_extractor.4.0.conv2        | Conv2d            | 36.9 K\n",
      "10  | feature_extractor.4.0.bn2          | BatchNorm2d       | 128   \n",
      "11  | feature_extractor.4.0.conv3        | Conv2d            | 16.4 K\n",
      "12  | feature_extractor.4.0.bn3          | BatchNorm2d       | 512   \n",
      "13  | feature_extractor.4.0.relu         | ReLU              | 0     \n",
      "14  | feature_extractor.4.0.downsample   | Sequential        | 16.9 K\n",
      "15  | feature_extractor.4.0.downsample.0 | Conv2d            | 16.4 K\n",
      "16  | feature_extractor.4.0.downsample.1 | BatchNorm2d       | 512   \n",
      "17  | feature_extractor.4.1              | Bottleneck        | 70.4 K\n",
      "18  | feature_extractor.4.1.conv1        | Conv2d            | 16.4 K\n",
      "19  | feature_extractor.4.1.bn1          | BatchNorm2d       | 128   \n",
      "20  | feature_extractor.4.1.conv2        | Conv2d            | 36.9 K\n",
      "21  | feature_extractor.4.1.bn2          | BatchNorm2d       | 128   \n",
      "22  | feature_extractor.4.1.conv3        | Conv2d            | 16.4 K\n",
      "23  | feature_extractor.4.1.bn3          | BatchNorm2d       | 512   \n",
      "24  | feature_extractor.4.1.relu         | ReLU              | 0     \n",
      "25  | feature_extractor.4.2              | Bottleneck        | 70.4 K\n",
      "26  | feature_extractor.4.2.conv1        | Conv2d            | 16.4 K\n",
      "27  | feature_extractor.4.2.bn1          | BatchNorm2d       | 128   \n",
      "28  | feature_extractor.4.2.conv2        | Conv2d            | 36.9 K\n",
      "29  | feature_extractor.4.2.bn2          | BatchNorm2d       | 128   \n",
      "30  | feature_extractor.4.2.conv3        | Conv2d            | 16.4 K\n",
      "31  | feature_extractor.4.2.bn3          | BatchNorm2d       | 512   \n",
      "32  | feature_extractor.4.2.relu         | ReLU              | 0     \n",
      "33  | feature_extractor.5                | Sequential        | 1.2 M \n",
      "34  | feature_extractor.5.0              | Bottleneck        | 379 K \n",
      "35  | feature_extractor.5.0.conv1        | Conv2d            | 32.8 K\n",
      "36  | feature_extractor.5.0.bn1          | BatchNorm2d       | 256   \n",
      "37  | feature_extractor.5.0.conv2        | Conv2d            | 147 K \n",
      "38  | feature_extractor.5.0.bn2          | BatchNorm2d       | 256   \n",
      "39  | feature_extractor.5.0.conv3        | Conv2d            | 65.5 K\n",
      "40  | feature_extractor.5.0.bn3          | BatchNorm2d       | 1.0 K \n",
      "41  | feature_extractor.5.0.relu         | ReLU              | 0     \n",
      "42  | feature_extractor.5.0.downsample   | Sequential        | 132 K \n",
      "43  | feature_extractor.5.0.downsample.0 | Conv2d            | 131 K \n",
      "44  | feature_extractor.5.0.downsample.1 | BatchNorm2d       | 1.0 K \n",
      "45  | feature_extractor.5.1              | Bottleneck        | 280 K \n",
      "46  | feature_extractor.5.1.conv1        | Conv2d            | 65.5 K\n",
      "47  | feature_extractor.5.1.bn1          | BatchNorm2d       | 256   \n",
      "48  | feature_extractor.5.1.conv2        | Conv2d            | 147 K \n",
      "49  | feature_extractor.5.1.bn2          | BatchNorm2d       | 256   \n",
      "50  | feature_extractor.5.1.conv3        | Conv2d            | 65.5 K\n",
      "51  | feature_extractor.5.1.bn3          | BatchNorm2d       | 1.0 K \n",
      "52  | feature_extractor.5.1.relu         | ReLU              | 0     \n",
      "53  | feature_extractor.5.2              | Bottleneck        | 280 K \n",
      "54  | feature_extractor.5.2.conv1        | Conv2d            | 65.5 K\n",
      "55  | feature_extractor.5.2.bn1          | BatchNorm2d       | 256   \n",
      "56  | feature_extractor.5.2.conv2        | Conv2d            | 147 K \n",
      "57  | feature_extractor.5.2.bn2          | BatchNorm2d       | 256   \n",
      "58  | feature_extractor.5.2.conv3        | Conv2d            | 65.5 K\n",
      "59  | feature_extractor.5.2.bn3          | BatchNorm2d       | 1.0 K \n",
      "60  | feature_extractor.5.2.relu         | ReLU              | 0     \n",
      "61  | feature_extractor.5.3              | Bottleneck        | 280 K \n",
      "62  | feature_extractor.5.3.conv1        | Conv2d            | 65.5 K\n",
      "63  | feature_extractor.5.3.bn1          | BatchNorm2d       | 256   \n",
      "64  | feature_extractor.5.3.conv2        | Conv2d            | 147 K \n",
      "65  | feature_extractor.5.3.bn2          | BatchNorm2d       | 256   \n",
      "66  | feature_extractor.5.3.conv3        | Conv2d            | 65.5 K\n",
      "67  | feature_extractor.5.3.bn3          | BatchNorm2d       | 1.0 K \n",
      "68  | feature_extractor.5.3.relu         | ReLU              | 0     \n",
      "69  | feature_extractor.6                | Sequential        | 7.1 M \n",
      "70  | feature_extractor.6.0              | Bottleneck        | 1.5 M \n",
      "71  | feature_extractor.6.0.conv1        | Conv2d            | 131 K \n",
      "72  | feature_extractor.6.0.bn1          | BatchNorm2d       | 512   \n",
      "73  | feature_extractor.6.0.conv2        | Conv2d            | 589 K \n",
      "74  | feature_extractor.6.0.bn2          | BatchNorm2d       | 512   \n",
      "75  | feature_extractor.6.0.conv3        | Conv2d            | 262 K \n",
      "76  | feature_extractor.6.0.bn3          | BatchNorm2d       | 2.0 K \n",
      "77  | feature_extractor.6.0.relu         | ReLU              | 0     \n",
      "78  | feature_extractor.6.0.downsample   | Sequential        | 526 K \n",
      "79  | feature_extractor.6.0.downsample.0 | Conv2d            | 524 K \n",
      "80  | feature_extractor.6.0.downsample.1 | BatchNorm2d       | 2.0 K \n",
      "81  | feature_extractor.6.1              | Bottleneck        | 1.1 M \n",
      "82  | feature_extractor.6.1.conv1        | Conv2d            | 262 K \n",
      "83  | feature_extractor.6.1.bn1          | BatchNorm2d       | 512   \n",
      "84  | feature_extractor.6.1.conv2        | Conv2d            | 589 K \n",
      "85  | feature_extractor.6.1.bn2          | BatchNorm2d       | 512   \n",
      "86  | feature_extractor.6.1.conv3        | Conv2d            | 262 K \n",
      "87  | feature_extractor.6.1.bn3          | BatchNorm2d       | 2.0 K \n",
      "88  | feature_extractor.6.1.relu         | ReLU              | 0     \n",
      "89  | feature_extractor.6.2              | Bottleneck        | 1.1 M \n",
      "90  | feature_extractor.6.2.conv1        | Conv2d            | 262 K \n",
      "91  | feature_extractor.6.2.bn1          | BatchNorm2d       | 512   \n",
      "92  | feature_extractor.6.2.conv2        | Conv2d            | 589 K \n",
      "93  | feature_extractor.6.2.bn2          | BatchNorm2d       | 512   \n",
      "94  | feature_extractor.6.2.conv3        | Conv2d            | 262 K \n",
      "95  | feature_extractor.6.2.bn3          | BatchNorm2d       | 2.0 K \n",
      "96  | feature_extractor.6.2.relu         | ReLU              | 0     \n",
      "97  | feature_extractor.6.3              | Bottleneck        | 1.1 M \n",
      "98  | feature_extractor.6.3.conv1        | Conv2d            | 262 K \n",
      "99  | feature_extractor.6.3.bn1          | BatchNorm2d       | 512   \n",
      "100 | feature_extractor.6.3.conv2        | Conv2d            | 589 K \n",
      "101 | feature_extractor.6.3.bn2          | BatchNorm2d       | 512   \n",
      "102 | feature_extractor.6.3.conv3        | Conv2d            | 262 K \n",
      "103 | feature_extractor.6.3.bn3          | BatchNorm2d       | 2.0 K \n",
      "104 | feature_extractor.6.3.relu         | ReLU              | 0     \n",
      "105 | feature_extractor.6.4              | Bottleneck        | 1.1 M \n",
      "106 | feature_extractor.6.4.conv1        | Conv2d            | 262 K \n",
      "107 | feature_extractor.6.4.bn1          | BatchNorm2d       | 512   \n",
      "108 | feature_extractor.6.4.conv2        | Conv2d            | 589 K \n",
      "109 | feature_extractor.6.4.bn2          | BatchNorm2d       | 512   \n",
      "110 | feature_extractor.6.4.conv3        | Conv2d            | 262 K \n",
      "111 | feature_extractor.6.4.bn3          | BatchNorm2d       | 2.0 K \n",
      "112 | feature_extractor.6.4.relu         | ReLU              | 0     \n",
      "113 | feature_extractor.6.5              | Bottleneck        | 1.1 M \n",
      "114 | feature_extractor.6.5.conv1        | Conv2d            | 262 K \n",
      "115 | feature_extractor.6.5.bn1          | BatchNorm2d       | 512   \n",
      "116 | feature_extractor.6.5.conv2        | Conv2d            | 589 K \n",
      "117 | feature_extractor.6.5.bn2          | BatchNorm2d       | 512   \n",
      "118 | feature_extractor.6.5.conv3        | Conv2d            | 262 K \n",
      "119 | feature_extractor.6.5.bn3          | BatchNorm2d       | 2.0 K \n",
      "120 | feature_extractor.6.5.relu         | ReLU              | 0     \n",
      "121 | feature_extractor.7                | Sequential        | 15.0 M\n",
      "122 | feature_extractor.7.0              | Bottleneck        | 6.0 M \n",
      "123 | feature_extractor.7.0.conv1        | Conv2d            | 524 K \n",
      "124 | feature_extractor.7.0.bn1          | BatchNorm2d       | 1.0 K \n",
      "125 | feature_extractor.7.0.conv2        | Conv2d            | 2.4 M \n",
      "126 | feature_extractor.7.0.bn2          | BatchNorm2d       | 1.0 K \n",
      "127 | feature_extractor.7.0.conv3        | Conv2d            | 1.0 M \n",
      "128 | feature_extractor.7.0.bn3          | BatchNorm2d       | 4.1 K \n",
      "129 | feature_extractor.7.0.relu         | ReLU              | 0     \n",
      "130 | feature_extractor.7.0.downsample   | Sequential        | 2.1 M \n",
      "131 | feature_extractor.7.0.downsample.0 | Conv2d            | 2.1 M \n",
      "132 | feature_extractor.7.0.downsample.1 | BatchNorm2d       | 4.1 K \n",
      "133 | feature_extractor.7.1              | Bottleneck        | 4.5 M \n",
      "134 | feature_extractor.7.1.conv1        | Conv2d            | 1.0 M \n",
      "135 | feature_extractor.7.1.bn1          | BatchNorm2d       | 1.0 K \n",
      "136 | feature_extractor.7.1.conv2        | Conv2d            | 2.4 M \n",
      "137 | feature_extractor.7.1.bn2          | BatchNorm2d       | 1.0 K \n",
      "138 | feature_extractor.7.1.conv3        | Conv2d            | 1.0 M \n",
      "139 | feature_extractor.7.1.bn3          | BatchNorm2d       | 4.1 K \n",
      "140 | feature_extractor.7.1.relu         | ReLU              | 0     \n",
      "141 | feature_extractor.7.2              | Bottleneck        | 4.5 M \n",
      "142 | feature_extractor.7.2.conv1        | Conv2d            | 1.0 M \n",
      "143 | feature_extractor.7.2.bn1          | BatchNorm2d       | 1.0 K \n",
      "144 | feature_extractor.7.2.conv2        | Conv2d            | 2.4 M \n",
      "145 | feature_extractor.7.2.bn2          | BatchNorm2d       | 1.0 K \n",
      "146 | feature_extractor.7.2.conv3        | Conv2d            | 1.0 M \n",
      "147 | feature_extractor.7.2.bn3          | BatchNorm2d       | 4.1 K \n",
      "148 | feature_extractor.7.2.relu         | ReLU              | 0     \n",
      "149 | feature_extractor.8                | AdaptiveAvgPool2d | 0     \n",
      "150 | classifier                         | Linear            | 20.5 K\n",
      "151 | criterion                          | CrossEntropyLoss  | 0     \n",
      "---------------------------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\phoen\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad638f3c5104981a7a4548d4feadd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386c407-bcc7-40ed-b8fa-d8d489e8d390",
   "metadata": {},
   "source": [
    "To print the model summary if .fit() is not called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec427ca2-9aa9-4985-8d4e-eece5ca1a3af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "summary = ModelSummary(model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66663d78-8c8c-4e5a-827f-119137515578",
   "metadata": {},
   "source": [
    "### Print input output layer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7ea9dda-8751-4654-9025-cc86f554ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=10, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.example_input_array = torch.Tensor(32, 3, 228, 228)\n",
    "        \n",
    "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        x = input_\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        return y_pred   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e3f220d-907c-48f4-a003-8254be3441fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Name                               | Type              | Params | In sizes           | Out sizes         \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0   | feature_extractor                  | Sequential        | 23.5 M | [32, 3, 228, 228]  | [32, 2048, 1, 1]  \n",
      "1   | feature_extractor.0                | Conv2d            | 9.4 K  | [32, 3, 228, 228]  | [32, 64, 114, 114]\n",
      "2   | feature_extractor.1                | BatchNorm2d       | 128    | [32, 64, 114, 114] | [32, 64, 114, 114]\n",
      "3   | feature_extractor.2                | ReLU              | 0      | [32, 64, 114, 114] | [32, 64, 114, 114]\n",
      "4   | feature_extractor.3                | MaxPool2d         | 0      | [32, 64, 114, 114] | [32, 64, 57, 57]  \n",
      "5   | feature_extractor.4                | Sequential        | 215 K  | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "6   | feature_extractor.4.0              | Bottleneck        | 75.0 K | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "7   | feature_extractor.4.0.conv1        | Conv2d            | 4.1 K  | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "8   | feature_extractor.4.0.bn1          | BatchNorm2d       | 128    | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "9   | feature_extractor.4.0.conv2        | Conv2d            | 36.9 K | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "10  | feature_extractor.4.0.bn2          | BatchNorm2d       | 128    | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "11  | feature_extractor.4.0.conv3        | Conv2d            | 16.4 K | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "12  | feature_extractor.4.0.bn3          | BatchNorm2d       | 512    | [32, 256, 57, 57]  | [32, 256, 57, 57] \n",
      "13  | feature_extractor.4.0.relu         | ReLU              | 0      | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "14  | feature_extractor.4.0.downsample   | Sequential        | 16.9 K | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "15  | feature_extractor.4.0.downsample.0 | Conv2d            | 16.4 K | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "16  | feature_extractor.4.0.downsample.1 | BatchNorm2d       | 512    | [32, 256, 57, 57]  | [32, 256, 57, 57] \n",
      "17  | feature_extractor.4.1              | Bottleneck        | 70.4 K | [32, 256, 57, 57]  | [32, 256, 57, 57] \n",
      "18  | feature_extractor.4.1.conv1        | Conv2d            | 16.4 K | [32, 256, 57, 57]  | [32, 64, 57, 57]  \n",
      "19  | feature_extractor.4.1.bn1          | BatchNorm2d       | 128    | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "20  | feature_extractor.4.1.conv2        | Conv2d            | 36.9 K | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "21  | feature_extractor.4.1.bn2          | BatchNorm2d       | 128    | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "22  | feature_extractor.4.1.conv3        | Conv2d            | 16.4 K | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "23  | feature_extractor.4.1.bn3          | BatchNorm2d       | 512    | [32, 256, 57, 57]  | [32, 256, 57, 57] \n",
      "24  | feature_extractor.4.1.relu         | ReLU              | 0      | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "25  | feature_extractor.4.2              | Bottleneck        | 70.4 K | [32, 256, 57, 57]  | [32, 256, 57, 57] \n",
      "26  | feature_extractor.4.2.conv1        | Conv2d            | 16.4 K | [32, 256, 57, 57]  | [32, 64, 57, 57]  \n",
      "27  | feature_extractor.4.2.bn1          | BatchNorm2d       | 128    | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "28  | feature_extractor.4.2.conv2        | Conv2d            | 36.9 K | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "29  | feature_extractor.4.2.bn2          | BatchNorm2d       | 128    | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "30  | feature_extractor.4.2.conv3        | Conv2d            | 16.4 K | [32, 64, 57, 57]   | [32, 256, 57, 57] \n",
      "31  | feature_extractor.4.2.bn3          | BatchNorm2d       | 512    | [32, 256, 57, 57]  | [32, 256, 57, 57] \n",
      "32  | feature_extractor.4.2.relu         | ReLU              | 0      | [32, 64, 57, 57]   | [32, 64, 57, 57]  \n",
      "33  | feature_extractor.5                | Sequential        | 1.2 M  | [32, 256, 57, 57]  | [32, 512, 29, 29] \n",
      "34  | feature_extractor.5.0              | Bottleneck        | 379 K  | [32, 256, 57, 57]  | [32, 512, 29, 29] \n",
      "35  | feature_extractor.5.0.conv1        | Conv2d            | 32.8 K | [32, 256, 57, 57]  | [32, 128, 57, 57] \n",
      "36  | feature_extractor.5.0.bn1          | BatchNorm2d       | 256    | [32, 128, 57, 57]  | [32, 128, 57, 57] \n",
      "37  | feature_extractor.5.0.conv2        | Conv2d            | 147 K  | [32, 128, 57, 57]  | [32, 128, 29, 29] \n",
      "38  | feature_extractor.5.0.bn2          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "39  | feature_extractor.5.0.conv3        | Conv2d            | 65.5 K | [32, 128, 29, 29]  | [32, 512, 29, 29] \n",
      "40  | feature_extractor.5.0.bn3          | BatchNorm2d       | 1.0 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "41  | feature_extractor.5.0.relu         | ReLU              | 0      | [32, 128, 57, 57]  | [32, 128, 57, 57] \n",
      "42  | feature_extractor.5.0.downsample   | Sequential        | 132 K  | [32, 256, 57, 57]  | [32, 512, 29, 29] \n",
      "43  | feature_extractor.5.0.downsample.0 | Conv2d            | 131 K  | [32, 256, 57, 57]  | [32, 512, 29, 29] \n",
      "44  | feature_extractor.5.0.downsample.1 | BatchNorm2d       | 1.0 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "45  | feature_extractor.5.1              | Bottleneck        | 280 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "46  | feature_extractor.5.1.conv1        | Conv2d            | 65.5 K | [32, 512, 29, 29]  | [32, 128, 29, 29] \n",
      "47  | feature_extractor.5.1.bn1          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "48  | feature_extractor.5.1.conv2        | Conv2d            | 147 K  | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "49  | feature_extractor.5.1.bn2          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "50  | feature_extractor.5.1.conv3        | Conv2d            | 65.5 K | [32, 128, 29, 29]  | [32, 512, 29, 29] \n",
      "51  | feature_extractor.5.1.bn3          | BatchNorm2d       | 1.0 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "52  | feature_extractor.5.1.relu         | ReLU              | 0      | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "53  | feature_extractor.5.2              | Bottleneck        | 280 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "54  | feature_extractor.5.2.conv1        | Conv2d            | 65.5 K | [32, 512, 29, 29]  | [32, 128, 29, 29] \n",
      "55  | feature_extractor.5.2.bn1          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "56  | feature_extractor.5.2.conv2        | Conv2d            | 147 K  | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "57  | feature_extractor.5.2.bn2          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "58  | feature_extractor.5.2.conv3        | Conv2d            | 65.5 K | [32, 128, 29, 29]  | [32, 512, 29, 29] \n",
      "59  | feature_extractor.5.2.bn3          | BatchNorm2d       | 1.0 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "60  | feature_extractor.5.2.relu         | ReLU              | 0      | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "61  | feature_extractor.5.3              | Bottleneck        | 280 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "62  | feature_extractor.5.3.conv1        | Conv2d            | 65.5 K | [32, 512, 29, 29]  | [32, 128, 29, 29] \n",
      "63  | feature_extractor.5.3.bn1          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "64  | feature_extractor.5.3.conv2        | Conv2d            | 147 K  | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "65  | feature_extractor.5.3.bn2          | BatchNorm2d       | 256    | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "66  | feature_extractor.5.3.conv3        | Conv2d            | 65.5 K | [32, 128, 29, 29]  | [32, 512, 29, 29] \n",
      "67  | feature_extractor.5.3.bn3          | BatchNorm2d       | 1.0 K  | [32, 512, 29, 29]  | [32, 512, 29, 29] \n",
      "68  | feature_extractor.5.3.relu         | ReLU              | 0      | [32, 128, 29, 29]  | [32, 128, 29, 29] \n",
      "69  | feature_extractor.6                | Sequential        | 7.1 M  | [32, 512, 29, 29]  | [32, 1024, 15, 15]\n",
      "70  | feature_extractor.6.0              | Bottleneck        | 1.5 M  | [32, 512, 29, 29]  | [32, 1024, 15, 15]\n",
      "71  | feature_extractor.6.0.conv1        | Conv2d            | 131 K  | [32, 512, 29, 29]  | [32, 256, 29, 29] \n",
      "72  | feature_extractor.6.0.bn1          | BatchNorm2d       | 512    | [32, 256, 29, 29]  | [32, 256, 29, 29] \n",
      "73  | feature_extractor.6.0.conv2        | Conv2d            | 589 K  | [32, 256, 29, 29]  | [32, 256, 15, 15] \n",
      "74  | feature_extractor.6.0.bn2          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "75  | feature_extractor.6.0.conv3        | Conv2d            | 262 K  | [32, 256, 15, 15]  | [32, 1024, 15, 15]\n",
      "76  | feature_extractor.6.0.bn3          | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "77  | feature_extractor.6.0.relu         | ReLU              | 0      | [32, 256, 29, 29]  | [32, 256, 29, 29] \n",
      "78  | feature_extractor.6.0.downsample   | Sequential        | 526 K  | [32, 512, 29, 29]  | [32, 1024, 15, 15]\n",
      "79  | feature_extractor.6.0.downsample.0 | Conv2d            | 524 K  | [32, 512, 29, 29]  | [32, 1024, 15, 15]\n",
      "80  | feature_extractor.6.0.downsample.1 | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "81  | feature_extractor.6.1              | Bottleneck        | 1.1 M  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "82  | feature_extractor.6.1.conv1        | Conv2d            | 262 K  | [32, 1024, 15, 15] | [32, 256, 15, 15] \n",
      "83  | feature_extractor.6.1.bn1          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "84  | feature_extractor.6.1.conv2        | Conv2d            | 589 K  | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "85  | feature_extractor.6.1.bn2          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "86  | feature_extractor.6.1.conv3        | Conv2d            | 262 K  | [32, 256, 15, 15]  | [32, 1024, 15, 15]\n",
      "87  | feature_extractor.6.1.bn3          | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "88  | feature_extractor.6.1.relu         | ReLU              | 0      | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "89  | feature_extractor.6.2              | Bottleneck        | 1.1 M  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "90  | feature_extractor.6.2.conv1        | Conv2d            | 262 K  | [32, 1024, 15, 15] | [32, 256, 15, 15] \n",
      "91  | feature_extractor.6.2.bn1          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "92  | feature_extractor.6.2.conv2        | Conv2d            | 589 K  | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "93  | feature_extractor.6.2.bn2          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "94  | feature_extractor.6.2.conv3        | Conv2d            | 262 K  | [32, 256, 15, 15]  | [32, 1024, 15, 15]\n",
      "95  | feature_extractor.6.2.bn3          | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "96  | feature_extractor.6.2.relu         | ReLU              | 0      | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "97  | feature_extractor.6.3              | Bottleneck        | 1.1 M  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "98  | feature_extractor.6.3.conv1        | Conv2d            | 262 K  | [32, 1024, 15, 15] | [32, 256, 15, 15] \n",
      "99  | feature_extractor.6.3.bn1          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "100 | feature_extractor.6.3.conv2        | Conv2d            | 589 K  | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "101 | feature_extractor.6.3.bn2          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "102 | feature_extractor.6.3.conv3        | Conv2d            | 262 K  | [32, 256, 15, 15]  | [32, 1024, 15, 15]\n",
      "103 | feature_extractor.6.3.bn3          | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "104 | feature_extractor.6.3.relu         | ReLU              | 0      | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "105 | feature_extractor.6.4              | Bottleneck        | 1.1 M  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "106 | feature_extractor.6.4.conv1        | Conv2d            | 262 K  | [32, 1024, 15, 15] | [32, 256, 15, 15] \n",
      "107 | feature_extractor.6.4.bn1          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "108 | feature_extractor.6.4.conv2        | Conv2d            | 589 K  | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "109 | feature_extractor.6.4.bn2          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "110 | feature_extractor.6.4.conv3        | Conv2d            | 262 K  | [32, 256, 15, 15]  | [32, 1024, 15, 15]\n",
      "111 | feature_extractor.6.4.bn3          | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "112 | feature_extractor.6.4.relu         | ReLU              | 0      | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "113 | feature_extractor.6.5              | Bottleneck        | 1.1 M  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "114 | feature_extractor.6.5.conv1        | Conv2d            | 262 K  | [32, 1024, 15, 15] | [32, 256, 15, 15] \n",
      "115 | feature_extractor.6.5.bn1          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "116 | feature_extractor.6.5.conv2        | Conv2d            | 589 K  | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "117 | feature_extractor.6.5.bn2          | BatchNorm2d       | 512    | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "118 | feature_extractor.6.5.conv3        | Conv2d            | 262 K  | [32, 256, 15, 15]  | [32, 1024, 15, 15]\n",
      "119 | feature_extractor.6.5.bn3          | BatchNorm2d       | 2.0 K  | [32, 1024, 15, 15] | [32, 1024, 15, 15]\n",
      "120 | feature_extractor.6.5.relu         | ReLU              | 0      | [32, 256, 15, 15]  | [32, 256, 15, 15] \n",
      "121 | feature_extractor.7                | Sequential        | 15.0 M | [32, 1024, 15, 15] | [32, 2048, 8, 8]  \n",
      "122 | feature_extractor.7.0              | Bottleneck        | 6.0 M  | [32, 1024, 15, 15] | [32, 2048, 8, 8]  \n",
      "123 | feature_extractor.7.0.conv1        | Conv2d            | 524 K  | [32, 1024, 15, 15] | [32, 512, 15, 15] \n",
      "124 | feature_extractor.7.0.bn1          | BatchNorm2d       | 1.0 K  | [32, 512, 15, 15]  | [32, 512, 15, 15] \n",
      "125 | feature_extractor.7.0.conv2        | Conv2d            | 2.4 M  | [32, 512, 15, 15]  | [32, 512, 8, 8]   \n",
      "126 | feature_extractor.7.0.bn2          | BatchNorm2d       | 1.0 K  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "127 | feature_extractor.7.0.conv3        | Conv2d            | 1.0 M  | [32, 512, 8, 8]    | [32, 2048, 8, 8]  \n",
      "128 | feature_extractor.7.0.bn3          | BatchNorm2d       | 4.1 K  | [32, 2048, 8, 8]   | [32, 2048, 8, 8]  \n",
      "129 | feature_extractor.7.0.relu         | ReLU              | 0      | [32, 512, 15, 15]  | [32, 512, 15, 15] \n",
      "130 | feature_extractor.7.0.downsample   | Sequential        | 2.1 M  | [32, 1024, 15, 15] | [32, 2048, 8, 8]  \n",
      "131 | feature_extractor.7.0.downsample.0 | Conv2d            | 2.1 M  | [32, 1024, 15, 15] | [32, 2048, 8, 8]  \n",
      "132 | feature_extractor.7.0.downsample.1 | BatchNorm2d       | 4.1 K  | [32, 2048, 8, 8]   | [32, 2048, 8, 8]  \n",
      "133 | feature_extractor.7.1              | Bottleneck        | 4.5 M  | [32, 2048, 8, 8]   | [32, 2048, 8, 8]  \n",
      "134 | feature_extractor.7.1.conv1        | Conv2d            | 1.0 M  | [32, 2048, 8, 8]   | [32, 512, 8, 8]   \n",
      "135 | feature_extractor.7.1.bn1          | BatchNorm2d       | 1.0 K  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "136 | feature_extractor.7.1.conv2        | Conv2d            | 2.4 M  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "137 | feature_extractor.7.1.bn2          | BatchNorm2d       | 1.0 K  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "138 | feature_extractor.7.1.conv3        | Conv2d            | 1.0 M  | [32, 512, 8, 8]    | [32, 2048, 8, 8]  \n",
      "139 | feature_extractor.7.1.bn3          | BatchNorm2d       | 4.1 K  | [32, 2048, 8, 8]   | [32, 2048, 8, 8]  \n",
      "140 | feature_extractor.7.1.relu         | ReLU              | 0      | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "141 | feature_extractor.7.2              | Bottleneck        | 4.5 M  | [32, 2048, 8, 8]   | [32, 2048, 8, 8]  \n",
      "142 | feature_extractor.7.2.conv1        | Conv2d            | 1.0 M  | [32, 2048, 8, 8]   | [32, 512, 8, 8]   \n",
      "143 | feature_extractor.7.2.bn1          | BatchNorm2d       | 1.0 K  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "144 | feature_extractor.7.2.conv2        | Conv2d            | 2.4 M  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "145 | feature_extractor.7.2.bn2          | BatchNorm2d       | 1.0 K  | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "146 | feature_extractor.7.2.conv3        | Conv2d            | 1.0 M  | [32, 512, 8, 8]    | [32, 2048, 8, 8]  \n",
      "147 | feature_extractor.7.2.bn3          | BatchNorm2d       | 4.1 K  | [32, 2048, 8, 8]   | [32, 2048, 8, 8]  \n",
      "148 | feature_extractor.7.2.relu         | ReLU              | 0      | [32, 512, 8, 8]    | [32, 512, 8, 8]   \n",
      "149 | feature_extractor.8                | AdaptiveAvgPool2d | 0      | [32, 2048, 8, 8]   | [32, 2048, 1, 1]  \n",
      "150 | classifier                         | Linear            | 20.5 K | [32, 2048]         | [32, 10]          \n",
      "151 | criterion                          | CrossEntropyLoss  | 0      | ?                  | ?                 \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "model = ImagenetTransferLearning()\n",
    "summary = ModelSummary(model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aae017-2f3d-41ed-94b6-2bad54b698a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
