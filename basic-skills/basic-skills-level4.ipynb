{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c72b164-a3e9-4bcd-8d09-57dc6fa03d20",
   "metadata": {},
   "source": [
    "## PytorchLightning: Image Classification using CIFAR10 and ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af180c05-b41b-49bb-938c-86eeaa357d56",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc88a00-f96d-4d03-b974-b2498ccff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501a8b1-7a85-4f2b-9296-6b0054274e4e",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541c456-c453-404f-9b02-14335a59f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = CIFAR10(os.getcwd(), download=True, train=True, transform=transforms.ToTensor())\n",
    "test_set = CIFAR10(os.getcwd(), download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0301520-f780-4f41-9143-452c3e17265c",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ea83c-50b6-4322-8e53-44641859e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(data_set) * 0.8)\n",
    "valid_set_size = len(data_set) - train_set_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator = seed)\n",
    "\n",
    "print(f\"Train size: {train_set_size}\")\n",
    "print(f\"Valid size: {valid_set_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8cd1-053a-4ba1-b2a3-494fb4824eba",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b08f3-e688-4902-a3ed-e7fa772119e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        \n",
    "        y_pred = self.classifier(representations)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684f1a8-2521-4ad9-8b32-582c8718a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImagenetTransferLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52a7b2-10f5-4182-b1bd-377f9b628e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 512)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 512)\n",
    "test_loader = DataLoader(test_set, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158c18c-f8aa-4ad2-9b70-73fd1956d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger('cifar10_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c3e6f-c3c5-455f-9546-f416baf7462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, \n",
    "                     default_root_dir=\"resnet50/\",\n",
    "                     enable_checkpointing=True,\n",
    "                     logger=tb_logger)\n",
    "\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de9bc3-a9b1-4d25-b0a0-79fcfa77c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335bf3-1f89-4464-9c0e-246a80dc8db3",
   "metadata": {},
   "source": [
    "### Adding argument parser for py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b0419-fe22-4b6a-81b0-56b1d2efd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f6429-09f9-47a2-a852-2e70ec5f15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer arguments\n",
    "parser.add_argument(\"--devices\", type=int, default=2)\n",
    "\n",
    "# Hyperparameters for the model\n",
    "parser.add_argument(\"--layer_1_dim\", type=int, default=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ae9c9-d53d-412b-9c20-48ef95c27f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the user inputs and defaults (returns a argparse.Namespace)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc0fea-ba5f-4cc1-9a19-bde7812f245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parsed arguments in your program\n",
    "trainer = Trainer(devices=args.devices)\n",
    "model = ImagenetTransferLearning(ImagenetTransferLearning=args.layer_1_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
